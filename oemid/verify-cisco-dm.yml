# Colonizer verify ID file for HPE Apollo 4200 Gen9 deployment for Digital Media repository
#
- hosts: gluster_nodes
  name: Verify nodes against Cisco UCS profile for Digital Media Repository
  become: yes
  vars_prompt:

  tasks:
    - assert:
        that:
          - ansible_processor_vcpus == 12
          - ansible_product_name == "UCSC-C240-M5L"
          - ansible_memtotal_mb >= 64000
          - ansible_architecture == 'x86_64'
          - ansible_system_vendor == 'Cisco Systems Inc'
          - ansible_distribution == 'RedHat'
          - ansible_distribution_major_version == '7'
        msg: "System {{ ansible_host }} does not conform to the required hardware / operatign system requirements!"

    - name: get subscription status
      shell: subscription-manager status
      register: sm_status_cmd
      changed_when: false

    - assert:
        that:
          - sm_status_cmd | success
          - "'Overall Status: Current' in sm_status_cmd.stdout"
        msg: "System {{ ansible_host }} is not subscribed!"

    - name: get enabled repositories
      shell: yum repolist enabled
      args:
        warn: no
      register: yum_repolist_cmd
      changed_when: false

    - assert:
        that:
          - yum_repolist_cmd | success
          - "yum_repolist_cmd.stdout | search('(?<!-)rhel-7-server-rpms/x86_64')"
          - "yum_repolist_cmd.stdout | search('rh-gluster-3-for-rhel-7-server-rpms/x86_64')"
          - "yum_repolist_cmd.stdout | search('rh-gluster-3-nfs-for-rhel-7-server-rpms/x86_64')"
          - "yum_repolist_cmd.stdout | search('rh-gluster-3-samba-for-rhel-7-server-rpms/x86_64')"
          - "yum_repolist_cmd.stdout | search('rhel-ha-for-rhel-7-server-rpms/x86_64')"
        msg: "System {{ ansible_host }} does not have the required repositories enabled. Please enable rhel-7-server-rpms, rh-gluster-3-for-rhel-7-server-rpms, rh-gluster-3-nfs-for-rhel-7-server-rpms,  rh-gluster-3-samba-for-rhel-7-server-rpms and rhel-ha-for-rhel-7-server-rpms!"


    - name: search for gluster and gluster-colonizer packages
      shell: yum list all redhat-storage-server gluster-colonizer gluster-zeroconf-avahi
      args:
        warn: no
      register: yum_list_gluster_pkgs_cmd
      changed_when: false

    - assert:
        that:
          - yum_list_gluster_pkgs_cmd | success
          - "yum_list_gluster_pkgs_cmd.stdout | search('redhat-storage-server.noarch')"
          - "yum_list_gluster_pkgs_cmd.stdout | search('gluster-colonizer.noarch')"
          - "yum_list_gluster_pkgs_cmd.stdout | search('gluster-zeroconf-avahi.noarch')"
        msg: "System {{ ansible_host }} does not have the redhat-storage-server, gluster-colonizer and/or gluster-zeroconf-avahi packages available!"

   - assert:
        that:
          - "{{ item | success }}"
        msg: "System {{ ansible_host }} does not have all 24 drives available"
      with_items:
        - "{{ hpssacli_pd_show_cmd.results }}"

#   - name: enumerate physical NVMe devices
#      shell: lsblk --output NAME /dev/nvme*
#      changed_when: false
#      register: lsblk_nvme_cmd

#    - assert:
#        that:
#          - "{{ lsblk_nvme_cmd.stdout.find('nvme0n1') }}"
#          - "{{ lsblk_nvme_cmd.stdout.find('nvme1n1') }}"
#        msg: "System {{ ansible_host }} does not have the required NVMe devices present. Please make sure they show up as /dev/nvme0n1 and /dev/nvme1n1 in the system."

    - name: search for iptables-services package
      shell: yum list installed iptables-services
      args:
        warn: no
      register: yum_list_installed_iptables_cmd
      changed_when: false
      failed_when: false

    - assert:
        that:
          - "'iptables-services.x86_64' not in yum_list_installed_iptables_cmd.stdout"
        msg: "System {{ ansible_host }} has the iptables-services package installed. Please remove it in favor of firewalld!"

    - assert:
        that:
          - ansible_eth0 is defined
          - ansible_eth1 is defined
          #- ansible_ens2f0 is defined
        msg: "System {{ ansible_host }} does not have the expected NICs available, is using a different driver or has the NICs in the wrong PCIe slots. Please ensure that minimally eno1, ens1f0 and ens2f0 are available."

    - assert:
        that:
          - ansible_eth0.active == true
          - ansible_eth0.device == ansible_default_ipv4.alias
        msg: "System {{ ansible_host }} does not use eth0 as it's management network."

    - assert:
        that:
          - ansible_eth1.active == true
          - ansible_ens1f0.speed == 10000
          #- ansible_ens2f0.active == true
          #- ansible_ens2f0.speed == 10000
        msg: "System {{ ansible_host }}'s network adapters eth1 has either not negotiated the correct connection speed or is disconnected"

    # Depends on presence of package python-dnf
    - name: Install dependency for ansible selinux management
      package:
        name: libselinux-python.x86_64
        state: present

    - selinux:
        policy: targeted
        state: enforcing
